{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extraction_features_typologie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8fhJvHzvYkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238149cf-165b-4c96-cca7-94e3fcef78df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "chemin = \"/content/drive/MyDrive/Stage Defense\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpK6bK2ZyhZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c536523a-14bb-4393-ab7d-943f5b2a7e29"
      },
      "source": [
        "!pip install spacy-transformers\n",
        "!python3 -m spacy download fr_dep_news_trf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy-transformers\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/58/e470e8217c1c93db41c50ef210e02f7302fbf252a56b66708f8ecb579aa3/spacy_transformers-1.0.3-py2.py3-none-any.whl\n",
            "Collecting transformers<4.7.0,>=3.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 8.4MB/s \n",
            "\u001b[?25hCollecting spacy<4.0.0,>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/da/61f934c6ae177a291c77246ef91a78cab44a2d76f79e6892ca7b17571adf/spacy-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 34.1MB/s \n",
            "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/86/a6786d24d1d8f3a6cff2c60b55a7e845725a94919cd94d270ea49d82e59b/spacy_alignments-0.8.3-cp37-cp37m-manylinux2014_x86_64.whl (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.1MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 33.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers) (4.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (0.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (2.11.3)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 196kB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (2.0.5)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (1.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/e8/1bc00eeff3faf1c50bde941f88a491a5c1128debb75dd8c913401e71585c/spacy_legacy-3.0.8-py2.py3-none-any.whl\n",
            "Collecting catalogue<2.1.0,>=2.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-transformers) (57.0.0)\n",
            "Collecting thinc<8.1.0,>=8.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6e/bd2da3d71ab2d175248949ac106fee09ae13bfaca39002eabdbd908b7440/thinc-8.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (619kB)\n",
            "\u001b[K     |████████████████████████████████| 624kB 32.3MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/ae/ecfa3e2dc267010fa320034be0eb3a8e683dc98dae7e70f92b41605b4d35/pathy-0.6.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.7.0,>=3.4.0->spacy-transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.7.0,>=3.4.0->spacy-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.7.0,>=3.4.0->spacy-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.7.0,>=3.4.0->spacy-transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.7.0,>=3.4.0->spacy-transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.7.0,>=3.4.0->spacy-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.7.0,>=3.4.0->spacy-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.7.0,>=3.4.0->spacy-transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<4.7.0,>=3.4.0->spacy-transformers) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-transformers) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-transformers) (5.1.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers, typer, pydantic, catalogue, srsly, spacy-legacy, thinc, pathy, spacy, spacy-alignments, spacy-transformers\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 huggingface-hub-0.0.8 pathy-0.6.0 pydantic-1.8.2 sacremoses-0.0.45 spacy-3.1.0 spacy-alignments-0.8.3 spacy-legacy-3.0.8 spacy-transformers-1.0.3 srsly-2.4.1 thinc-8.0.7 tokenizers-0.10.3 transformers-4.6.1 typer-0.3.2\n",
            "2021-07-12 11:55:30.486621: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting fr-dep-news-trf==3.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_dep_news_trf-3.1.0/fr_dep_news_trf-3.1.0-py3-none-any.whl (400.7MB)\n",
            "\u001b[K     |████████████████████████████████| 400.7MB 36kB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from fr-dep-news-trf==3.1.0) (3.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from fr-dep-news-trf==3.1.0) (3.17.3)\n",
            "Requirement already satisfied: spacy-transformers<1.1.0,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from fr-dep-news-trf==3.1.0) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (4.41.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (0.3.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (57.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (8.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (20.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->fr-dep-news-trf==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (0.8.3)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: transformers<4.7.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (4.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.0.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->fr-dep-news-trf==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (4.6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (0.0.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.7.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.3->fr-dep-news-trf==3.1.0) (1.0.1)\n",
            "Installing collected packages: sentencepiece, fr-dep-news-trf\n",
            "Successfully installed fr-dep-news-trf-3.1.0 sentencepiece-0.1.91\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_dep_news_trf')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfBulrfExZOQ"
      },
      "source": [
        "\n",
        "\n",
        "import spacy\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcP9_0ZH2-Ol"
      },
      "source": [
        "chemin = \"/content/drive/MyDrive/Stage Defense\"\n",
        "nlp = spacy.load('fr_dep_news_trf')\n",
        "cheminmodeleW2V = \"https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWac_no_postag_no_phrase_500_cbow_cut100.bin\"\n",
        "model_frWac = gensim.models.KeyedVectors.load_word2vec_format(cheminmodeleW2V, binary=True, unicode_errors=\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjXM2XgbxekJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe9925e-a7bf-4e1a-b228-2c09b365542e"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "# stopwords de nltk\n",
        "nltk_stopwords = set(stopwords.words('french'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px_IDVA7zgmF",
        "outputId": "9faa484e-48af-47c1-ba8c-dae24eadda5a"
      },
      "source": [
        "nltk_stopwords = nltk_stopwords |{\"ni\"}\n",
        "\"ni\" in nltk_stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4W_ild50jO3"
      },
      "source": [
        "chemin = \"/content/drive/MyDrive/Stage Defense\"\n",
        "chemindata = chemin+\"/Corpus/Toutes_mentions_Defense_annotees.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6NNlOOr0_mX"
      },
      "source": [
        "# Pré-traitement corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AbjUdUQ1EMa"
      },
      "source": [
        "df = pd.read_csv(chemindata,sep=\",\", index_col=0, keep_default_na=False,na_values=[\"NA\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MXScErM4op0"
      },
      "source": [
        "df = df[(df.cible_contexte != \"\")&(df.procédé_de_nommage!= \"\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm6DLNnnT2j9"
      },
      "source": [
        "df_mention_w2v =  pd.DataFrame(liste_vecteurs_m,index=df.index)\n",
        "df_contexte_w2v =  pd.DataFrame(liste_vecteurs_c,index=df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTRMu_np9rno"
      },
      "source": [
        "mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q286RhB08Vq"
      },
      "source": [
        "def cree_vecteurs_designations(df):\n",
        "  liste_vecteurs_m = []\n",
        "  for mention in df.mention:\n",
        "    doc = nlp(mention)\n",
        "    if \"défense\" in mention.lower():\n",
        "      print(\"BRUT\",mention)\n",
        "    lemmes = [t.lemma_ for t in doc if t.lemma_ not in nltk_stopwords|{\"défense\",\"defense\"}]\n",
        "    array_vec = np.array([model_frWac[lem] for lem in lemmes if (lem in model_frWac.vocab )])\n",
        "    #print(array_vec.shape)\n",
        "    if not array_vec.any():\n",
        "      array_vec = np.zeros((1,500))\n",
        "    array_moy = np.mean(array_vec,axis=0)\n",
        "    liste_vecteurs_m.append(array_moy)\n",
        "  return liste_vecteurs_m \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a61AvszEwzI"
      },
      "source": [
        "liste_vecteurs_m = cree_vecteurs_designations(df)\n",
        "df_mention_w2v =  pd.DataFrame(liste_vecteurs_m,index=df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYmPvn93SijO"
      },
      "source": [
        "df_w2v = df_mention_w2v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKPO77V02UT3"
      },
      "source": [
        " df_w2v.columns = list(range(len(df_w2v.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdZikZl4UOJ8"
      },
      "source": [
        "df_w2v.to_csv(chemin+\"/Corpus/W2V_mentions_Defense.csv\",sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrR_NN78y3tO"
      },
      "source": [
        "#Descripteurs Linguistiques fins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqIdzhT_oLdP"
      },
      "source": [
        "\n",
        "import gensim\n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2KkTrW6oPtU"
      },
      "source": [
        "def moyenne_vecteurs(liste_mots):\n",
        "  liste_vecteurs = []\n",
        "  for mot in liste_mots:\n",
        "    if mot in model_frWac.vocab:\n",
        "      liste_vecteurs.append(model_frWac[mot])\n",
        "  print(len(liste_vecteurs))\n",
        "  return np.mean(np.array(liste_vecteurs),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQmAdgxpn6IB"
      },
      "source": [
        "def normalise(char):\n",
        "  char = re.sub(\"[],\\-\\n;&]\", \" \" , char)\n",
        "  return char.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzvJpIHo1i5F"
      },
      "source": [
        "def normalise_mention(men):\n",
        "  #men = men.lower()\n",
        "  men = re.sub(\"^-\",\"\",men)\n",
        "  men = men.replace(\"(\",\" (\")\n",
        "  men = men.replace(\")\",\")\")\n",
        "  return re.sub(\"\\s+\",\" \",men).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTkCcLTChQsz"
      },
      "source": [
        "def detecte_norme(mention):\n",
        "  stopwords = nltk_stopwords | {\"entre\",\"vers\",\"ni\"}\n",
        "  if \"défense\" in mention.lower() or \"defense\" in mention.lower():\n",
        "    doc = nlp(normalise(mention))\n",
        "    lemmes = [t.lemma_ for t in doc if t.lemma_ not in stopwords and re.match(\"\\w+\",t.lemma_)]\n",
        "    #print(lemmes)\n",
        "    if lemmes in  [[\"défense\"],[\"defense\"]]:\n",
        "      return 1\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKDocknNjeLs"
      },
      "source": [
        "def cos_sim(a,b):\n",
        "  return cosine_similarity(a.reshape(1, -1),b.reshape(1, -1))[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkpxWMW7flLQ"
      },
      "source": [
        "def contient_ordinal(mention):\n",
        "  ordinal = re.compile(\"((derni)|(premi)((er)|(ère)))|(seconde?)|((deux|trois|quatri|cinqu|six|sept|huit|neuv|dix|vingt|trente|cent|mill)ième)\")\n",
        "  if ordinal.search(mention.lower()):\n",
        "    return 1\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vho86jEmfot5"
      },
      "source": [
        "def contient_superlatif(mention):\n",
        "  set_superlatifs = {\"plus \",\"meilleur \",\"moins \",\"pire \",\"favori\",\"préféré\",\"moindre\"}\n",
        "  if any(super in mention.lower() for super in set_superlatifs):\n",
        "    return 1\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjAnKBISfSYN"
      },
      "source": [
        "def contient_lieu_geo(mention,vecteur_lieu,vecteur_geo):\n",
        "  #if True or \"laboratoire\" not in mention and \"mélange\" not in mention: return 0,0,0,0,0\n",
        "  #ajouter est type de lieu. Seuil = 0.30 Regarder tous les noms\n",
        "  doc = nlp(mention)\n",
        "  #print(doc[1].dep_)\n",
        "  lieu,geo = 0,0\n",
        "  sim_tete_lieu, sim_tete_geo,sim_tete_norme = 0,0,0\n",
        "  for tok in doc:\n",
        "    #print(tok,tok.pos_, tok.dep_, tok.tag_)\n",
        "    lemme = tok.lemma_.lower()\n",
        "    if lemme in model_frWac:\n",
        "      sim_lieu = cos_sim(model_frWac[lemme],vecteur_lieu)\n",
        "      sim_geo = cos_sim(model_frWac[lemme],vecteur_geo)\n",
        "      if sim_geo > 0.40:\n",
        "        \n",
        "        geo = 1\n",
        "      if sim_lieu > 0.40 and tok.pos_ in {\"NOUN\",\"PROPN\"}:\n",
        "        lieu = 1\n",
        "        #print( tok.dep_, tok.pos_,sim_lieu,tok.lemma_, mention)\n",
        "      #print(tok.dep_, tok.text)\n",
        "      \n",
        "      if (tok.dep_ == \"ROOT\" and all([tok.dep_ != \"appos\" for tok in doc ])) or tok.dep_ == \"appos\":\n",
        "        #print(tok,tok.dep_, \"|\",mention)\n",
        "        sim_tete_lieu = sim_lieu\n",
        "        sim_tete_geo = sim_geo\n",
        "        sim_tete_norme = cos_sim(model_frWac[lemme],model_frWac[\"défense\"])\n",
        "\n",
        "  if sim_tete_lieu == 0:\n",
        "    pass\n",
        "    print(mention, [t for t in doc if t.dep_ == \"ROOT\"])\n",
        "  return lieu,geo, sim_tete_lieu, sim_tete_geo,sim_tete_norme\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yp4VaTl7Va3"
      },
      "source": [
        "def contient_guillemet(mention):\n",
        "\n",
        "  return int('\"' in mention or '»' in mention or '«' in mention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NakyECY8obO_"
      },
      "source": [
        "types_lieux = {\"quartier\",\"zone\",\"lieu\",\"espace\",\"endroit\",\"ville\",\"localité\",\"village\",\"commune\",\"agglomération\",\"bourgade\",\"cité\",\"ghetto\",\"arrondissement\",\"terrain\",\"surface\"}\n",
        "geos = {\"france\",\"europe\",\"européen\",\"hauts-de-seine\",\"continental\",\"continent\",\"français\",\"paris\",\"parisien\"\"européen\",\"francilien\",\"parisien\",\"puteaux\",\"nanterre\",\"nanterrien\",\"putéolien\",\"courbevoie\",\"courbevoisien\",\"garenne-colombes\",\"seine\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29RU2ynjJ9EX",
        "outputId": "65c47b43-7a68-4ac6-eae7-d51e71aff306"
      },
      "source": [
        "vecteur_geo = moyenne_vecteurs([mot.strip(\"\\n\").lower() for mot in open(chemin+\"/Ressources/liste_pays.txt\", encoding=\"utf8\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4eDzobioE1q",
        "outputId": "929cf7b4-04be-42bc-a7fd-31e8d64ed142"
      },
      "source": [
        "vecteur_lieu = moyenne_vecteurs(types_lieux)\n",
        "vecteur_geo =  moyenne_vecteurs(geos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4JYTqCinIIT",
        "outputId": "10548190-76ae-4b9d-dcc0-cbe92ed33a50"
      },
      "source": [
        "def cree_features_mention(df):\n",
        "  data = []\n",
        "  for i  in df.index:\n",
        "    mention = df.loc[i,\"mention\"]\n",
        "    \n",
        "    if i%10 == 0 :\n",
        "      print(i)\n",
        "    mention= normalise_mention(mention)\n",
        "    is_norme = detecte_norme(mention)\n",
        "    is_lieu,is_geo,dist_lieu,dist_geo,dist_norme = contient_lieu_geo(mention,vecteur_lieu,vecteur_geo)\n",
        "    #dist_lieu,dist_geo,dist_norme = distances_procedes(mention,vecteur_lieu,vecteur_geo)\n",
        "    data.append([is_norme,contient_ordinal(mention),contient_superlatif(mention),is_lieu,dist_lieu,is_geo,dist_geo,dist_norme,contient_guillemet(mention)])\n",
        "\n",
        "  return pd.DataFrame(data,index=df.index,columns=[\"is_norme\",\"contient_ordinal\",\"contient_superlatif\",\"contient_lieu\",\"distance_lieu\",\"contient_geo\",\"distance_geo\",\"distance_norme\",\"contient_guillemet\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "le « meilleur site d'Europe »\n",
            "la « City » des Hauts-de-Seine\n",
            "la « City » des Hauts-de-Seine\n",
            "« coeur battant économique de la région »\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8CRAaeYisPJ"
      },
      "source": [
        "df_features = cree_features_mention(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmryN43Wpt69"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glz9geJwqmwS"
      },
      "source": [
        "df_features.to_csv(chemin+\"/Corpus/features_mentions_Defense.csv\",sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "4XSFVVOXs1TW",
        "outputId": "2cceced4-954a-49ea-e99d-de16a458b083"
      },
      "source": [
        "df_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_norme</th>\n",
              "      <th>contient_ordinal</th>\n",
              "      <th>contient_superlatif</th>\n",
              "      <th>contient_lieu</th>\n",
              "      <th>distance_lieu</th>\n",
              "      <th>contient_geo</th>\n",
              "      <th>distance_geo</th>\n",
              "      <th>distance_norme</th>\n",
              "      <th>contient_guillemet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.760152</td>\n",
              "      <td>1</td>\n",
              "      <td>0.272843</td>\n",
              "      <td>0.057394</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.072646</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.051843</td>\n",
              "      <td>-0.157264</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.760152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.272843</td>\n",
              "      <td>0.057394</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1462</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336291</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>827 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      is_norme  contient_ordinal  ...  distance_norme  contient_guillemet\n",
              "1            0                 1  ...        0.057394                   0\n",
              "2            1                 0  ...        1.000000                   0\n",
              "3            1                 0  ...        1.000000                   0\n",
              "4            0                 0  ...       -0.157264                   0\n",
              "5            1                 0  ...        1.000000                   0\n",
              "...        ...               ...  ...             ...                 ...\n",
              "1458         1                 0  ...        1.000000                   0\n",
              "1459         1                 0  ...        1.000000                   0\n",
              "1460         0                 0  ...        0.057394                   0\n",
              "1461         1                 0  ...        1.000000                   0\n",
              "1462         1                 0  ...        1.000000                   0\n",
              "\n",
              "[827 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}