{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_typologie_mention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWej5PIeUkSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2c311a-69aa-48cc-b9bf-56cca69df2ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yStzFrSV5Nh5",
        "outputId": "ff8e47a4-eb1b-4ba3-94db-69322e170bc3"
      },
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727026 sha256=1d9788fceed78ad358b689bba59b47a62b4396ca7d1145684d652981cd5946da\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rop4j4lj/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptNzStLqTgf7"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjusRvUjTiUW"
      },
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEFPe4IUsNj"
      },
      "source": [
        "\n",
        "import spacy\n",
        "nlp = spacy.load('fr_core_news_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFy-O6KuU9Wr"
      },
      "source": [
        "chemincorpus = \"/content/drive/MyDrive/Stage Defense/Corpus/\"\n",
        "cheminw2v = chemincorpus + 'W2V_mentions_Defense.csv'\n",
        "cheminbow = chemincorpus + 'BoW_mentions_Defense.csv'\n",
        "cheminfeatures = chemincorpus +\"features_mentions_Defense.csv\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nJ9xMp5Wb7b"
      },
      "source": [
        "Fonctions utiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY43qlPCWQiE"
      },
      "source": [
        "def equilibre_classes(X,y):\n",
        "  '''Retire aléatoirement des exemples des classes surnnuméraires, à la fois dans X et dans y\n",
        "  Renvoie X et y avec toutes les classes ayant le meme nombre d'exemple que la classe minoritaire'''\n",
        "  dicoclasses = {k:v for k,v in zip(*np.unique(y, return_counts=True))}\n",
        "  print(\"avant\",dicoclasses)\n",
        "  mini = min(dicoclasses.values())\n",
        "  while any((v >mini for v in dicoclasses.values())):\n",
        "    \n",
        "    for cat in dicoclasses:\n",
        "      if dicoclasses[cat] > mini:\n",
        "        nb_hasard = np.random.choice(np.where(y==cat)[0],1)\n",
        "        X = np.delete(X,nb_hasard, axis=0)\n",
        "        y = np.delete(y,nb_hasard, axis=0)\n",
        "        dicoclasses[cat]-=1\n",
        "\n",
        "  print(\"apres\",dicoclasses)\n",
        "  return X,y\n",
        "  #for i in range(len(X)):\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4jfaskQWeS6"
      },
      "source": [
        "def aff_res(cm,model):\n",
        "    '''\n",
        "    cm est la matrice de confusion\n",
        "    classes est la liste des classes, obtenue par model.classes_ (où model est le modèle de classification généré)\n",
        "    '''\n",
        "\n",
        "    #%matplotlib inline\n",
        "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "    \n",
        "    class_names = model.classes_\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    # create heatmap\n",
        "    sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "    \n",
        "    #set label names\n",
        "    ax.xaxis.set_label_position(\"top\")\n",
        "    ax.xaxis.set_ticklabels(class_names)\n",
        "    ax.yaxis.set_ticklabels(class_names)\n",
        "    \n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIcftOBuXESR"
      },
      "source": [
        "Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Zy4vn6XZiD"
      },
      "source": [
        "dfbow = pd.read_csv(cheminbow, sep=\",\",index_col=0)\n",
        "dfw2v = pd.read_csv(cheminw2v, sep=\",\",index_col=0)\n",
        "dffeatures = pd.read_csv(cheminfeatures, sep=\",\",index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WlRVNGFeEO5"
      },
      "source": [
        "chemindata = chemincorpus+\"Toutes_mentions_Defense_annotees.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPUNMe4_eRYA"
      },
      "source": [
        "dfannot = pd.read_csv(chemindata,sep=\",\", index_col=0, keep_default_na=False,na_values=[\"NA\"])\n",
        "annotations = dfannot.loc[:,:\"positionnement_contexte\"]\n",
        "annotations = annotations.fillna(\"NA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxLUrWEbD5c3",
        "outputId": "bf456bd6-2cea-4b4f-8513-7e89f07551c5"
      },
      "source": [
        "annotations.mention[annotations.mention.str.contains(\"froid\")]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109        des tours de bureaux froides et impersonnelles\n",
              "1391                          d'un quartier froid et vide\n",
              "1496    comme un quartier uniquement dédié au travail,...\n",
              "Name: mention, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpcI-8wjsF-t",
        "outputId": "17ac7ebc-93ed-45cf-ba0e-c7e115b16b35"
      },
      "source": [
        "dfbow.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   1,    2,    3,    4,    5,    6,    9,   10,   11,   12,\n",
              "            ...\n",
              "            1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462],\n",
              "           dtype='int64', length=827)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsIoJ9SCncd_"
      },
      "source": [
        "annotations = annotations.loc[dfbow.index,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KDcXMlZGgg"
      },
      "source": [
        "X_bow_mention = dfbow.iloc[:,:159]\n",
        "X_bow_contexte = dfbow.iloc[:,160:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cs8AdY6XJQr"
      },
      "source": [
        "X_w2v_mention = dfw2v.iloc[:,:500]\n",
        "X_w2v_contexte = dfw2v.iloc[:,501:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfpYQfc2Xu4l"
      },
      "source": [
        "# Predictions mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zv7wBNfao-g"
      },
      "source": [
        "def validation_croisee(X,y,clf):\n",
        "  y_pred = cross_val_predict(clf,X,y=y)\n",
        "  report = classification_report(y,y_pred)\n",
        "  print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDebb27xDxAO"
      },
      "source": [
        "def split_labels(y):\n",
        "  newy = []\n",
        "  for labels in y:\n",
        "    labelsplit = [label.strip() for label in labels.split(\"/\")]\n",
        "    if labelsplit == ['']:\n",
        "      print(labels)\n",
        "    newy.append(labelsplit)\n",
        "  return newy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V_yOxaFeT4M"
      },
      "source": [
        "## Procédé_nommage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dp_VpTPHXuU"
      },
      "source": [
        "### Extraction de la Norme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzr5i7zoeZ9z"
      },
      "source": [
        "def separe_norme(dffeatures):\n",
        "  index_normes = []\n",
        "  for i in dffeatures.index:\n",
        "    if dffeatures.loc[i,\"is_norme\"]:\n",
        "      index_normes.append(i)\n",
        "      #print(y.iloc[i,0])\n",
        "  return index_normes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js_M-7sLgolO"
      },
      "source": [
        "index_normes = separe_norme(dffeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoBGgbrBwnpD"
      },
      "source": [
        "df_pred = pd.DataFrame(index=annotations.index)\n",
        "df_pred[\"procédé_de_nommage\"] = \"autre\"\n",
        "df_pred[df_pred.index.isin(index_normes)]=\"norme\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZblc6Byk0y"
      },
      "source": [
        "index_not_norme = annotations[~annotations.index.isin(index_normes)].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2n0ExuP-ORm"
      },
      "source": [
        "y_norme_autre = annotations.loc[:,\"procédé_de_nommage\"].copy()\n",
        "y_norme_autre.loc[index_not_norme] = \"autre\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hHQ5g0HINTy",
        "outputId": "cdb507fd-3de5-45cb-fc94-ea5de89e9152"
      },
      "source": [
        "print(classification_report(df_pred.procédé_de_nommage,y_norme_autre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       autre       1.00      1.00      1.00       439\n",
            "       norme       1.00      1.00      1.00       388\n",
            "\n",
            "    accuracy                           1.00       827\n",
            "   macro avg       1.00      1.00      1.00       827\n",
            "weighted avg       1.00      1.00      1.00       827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ8JTKLU-RTk"
      },
      "source": [
        "### Autres procédés de nommage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1mmXSl_38QY"
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiaKtdM8HdGF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aox4Nd7Qx_iY"
      },
      "source": [
        "Préparation données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq_JOdsMo8-Y"
      },
      "source": [
        "#### Descripteurs Linguistiques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyZB6oCBohHi"
      },
      "source": [
        "Symbolique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCDIKyer_BRP"
      },
      "source": [
        "def classifie_procédés(X):\n",
        "  y_pred_symbo = []\n",
        "  for ordi,super,lieu,dist_lieu,geo,dist_geo,dist_norme in  X:\n",
        "    labels = [0,0,0,0]\n",
        "    if ordi or super:\n",
        "      labels[0] = 1\n",
        "    if lieu :\n",
        "      labels[3] = 1\n",
        "    if geo : \n",
        "      labels[2] = 1\n",
        "    if all([dist < 0.50 for dist in {dist_lieu,dist_geo,dist_norme}]):\n",
        "      labels[1] = 1\n",
        "    y_pred_symbo.append(labels)\n",
        "  return y_pred_symbo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VjMtEOZXBhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80440ca3-e154-437e-c99e-f07d84ac63b3"
      },
      "source": [
        "y_pred_symbo = classifie_procédés(X_procédé)\n",
        "report = classification_report(y_procédé,y_pred_symbo,target_names=MB.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk0w5ZIDbgpV",
        "outputId": "03c71781-75c1-4cd1-9c0a-b8d39555e5f2"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            classement       1.00      0.96      0.98        23\n",
            "             métaphore       0.85      0.85      0.85        20\n",
            "référence géographique       0.99      0.97      0.98        68\n",
            "             type lieu       0.93      0.96      0.95        57\n",
            "\n",
            "             micro avg       0.95      0.95      0.95       168\n",
            "             macro avg       0.94      0.94      0.94       168\n",
            "          weighted avg       0.95      0.95      0.95       168\n",
            "           samples avg       0.95      0.95      0.94       168\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLStNslBYgzo"
      },
      "source": [
        "## Cible_mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlZS2OGyLtaw"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGdEDe08K9TA"
      },
      "source": [
        "def reequilibre_classes(X,y,cible_support):\n",
        "  \n",
        "  classes,counts = np.unique(np.array([label  for labels in y for label in labels]),return_counts=True)\n",
        "  dico_counts = {classe: count for classe,count in zip(classes,counts)}\n",
        "  dico_counts = dict(sorted(dico_counts.items(),key=lambda x:x[1] , reverse=True))\n",
        "  print(\"avant\", dico_counts)\n",
        "  #print(X)\n",
        "\n",
        "  new_X,new_y = [], []\n",
        "  if not isinstance(X,list):\n",
        "    X= X.tolist()\n",
        "  nb_sup,nb_add = 0,0\n",
        "  nb_total = len(X)\n",
        "  for label in dico_counts:\n",
        "    print(label,\"avant\", dico_counts)\n",
        "    while dico_counts[label]  < cible_support   or dico_counts[label]  > cible_support:\n",
        "      i = random.randint(0,len(y)-1)\n",
        "      labels = y[i]\n",
        "      if label not in labels : continue\n",
        "      if dico_counts[label] < cible_support :\n",
        "        for lab in labels:\n",
        "          dico_counts[lab] +=1\n",
        "        X.append(X[i])\n",
        "        y.append(y[i])\n",
        "        nb_add +=1\n",
        "      elif dico_counts[label] > cible_support :\n",
        "        if any((dico_counts[lab] < cible_support-5 for lab in labels) ): continue\n",
        "        for lab in labels:\n",
        "          dico_counts[lab] -=1\n",
        "        del X[i]\n",
        "        del y[i]\n",
        "        nb_sup+=1\n",
        "    \n",
        "    print(label,\"après\", dico_counts)\n",
        "\n",
        "  classes,counts = np.unique(np.array([label  for labels in y for label in labels]),return_counts=True)\n",
        "  dico_counts = {classe: count for classe,count in zip(classes,counts)}\n",
        "  print(f\"exemples avant : {nb_total}\", f\"ajoutés : {nb_add}\", f\"supprimés : {nb_sup}\", f\"exemples après : {len(X)}\", sep = \" | \")\n",
        "  return X,y\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  new_dico_counts =   {classe: count for classe,count in zip(*np.unique(np.array([label  for labels in new_y for label in labels]),return_counts=True))}\n",
        "  print(\"a la fin\",new_dico_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emHBcNivJbVY"
      },
      "source": [
        "Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuUaQ6Z8YlPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763c1a79-1762-4767-e87d-9270fd389691"
      },
      "source": [
        "X_cible_m = X_w2v_mention.loc[index_not_norme,:].to_numpy()\n",
        "y_cible_m = split_labels(annotations.loc[index_not_norme,:].cible_mention)\n",
        "X_cible_m, y_cible_m =reequilibre_classes(X_cible_m,y_cible_m,15)\n",
        "MB = MultiLabelBinarizer()\n",
        "y_cible_m = MB.fit_transform(y_cible_m)\n",
        "X_cible_m,y_cible_m = shuffle(X_cible_m,y_cible_m)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avant {'économie': 336, 'urbanisme': 59, 'localisation': 55, 'architecture': 19, 'espace de vie': 14, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "économie avant {'économie': 336, 'urbanisme': 59, 'localisation': 55, 'architecture': 19, 'espace de vie': 14, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "économie après {'économie': 15, 'urbanisme': 57, 'localisation': 21, 'architecture': 17, 'espace de vie': 12, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "urbanisme avant {'économie': 15, 'urbanisme': 57, 'localisation': 21, 'architecture': 17, 'espace de vie': 12, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "urbanisme après {'économie': 15, 'urbanisme': 15, 'localisation': 20, 'architecture': 17, 'espace de vie': 10, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "localisation avant {'économie': 15, 'urbanisme': 15, 'localisation': 20, 'architecture': 17, 'espace de vie': 10, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "localisation après {'économie': 15, 'urbanisme': 15, 'localisation': 15, 'architecture': 17, 'espace de vie': 10, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "architecture avant {'économie': 15, 'urbanisme': 15, 'localisation': 15, 'architecture': 17, 'espace de vie': 10, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "architecture après {'économie': 15, 'urbanisme': 15, 'localisation': 15, 'architecture': 15, 'espace de vie': 10, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "espace de vie avant {'économie': 15, 'urbanisme': 15, 'localisation': 15, 'architecture': 15, 'espace de vie': 10, 'taille': 8, 'changement': 6, 'disparité': 4}\n",
            "espace de vie après {'économie': 15, 'urbanisme': 15, 'localisation': 16, 'architecture': 15, 'espace de vie': 15, 'taille': 9, 'changement': 6, 'disparité': 4}\n",
            "taille avant {'économie': 15, 'urbanisme': 15, 'localisation': 16, 'architecture': 15, 'espace de vie': 15, 'taille': 9, 'changement': 6, 'disparité': 4}\n",
            "taille après {'économie': 20, 'urbanisme': 15, 'localisation': 21, 'architecture': 15, 'espace de vie': 16, 'taille': 15, 'changement': 6, 'disparité': 4}\n",
            "changement avant {'économie': 20, 'urbanisme': 15, 'localisation': 21, 'architecture': 15, 'espace de vie': 16, 'taille': 15, 'changement': 6, 'disparité': 4}\n",
            "changement après {'économie': 20, 'urbanisme': 15, 'localisation': 21, 'architecture': 15, 'espace de vie': 16, 'taille': 15, 'changement': 15, 'disparité': 4}\n",
            "disparité avant {'économie': 20, 'urbanisme': 15, 'localisation': 21, 'architecture': 15, 'espace de vie': 16, 'taille': 15, 'changement': 15, 'disparité': 4}\n",
            "disparité après {'économie': 21, 'urbanisme': 15, 'localisation': 21, 'architecture': 25, 'espace de vie': 17, 'taille': 15, 'changement': 15, 'disparité': 15}\n",
            "exemples avant : 439 | ajoutés : 31 | supprimés : 370 | exemples après : 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJIEM9rPZSBm"
      },
      "source": [
        "Apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBjXbEHcQx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6871777f-5618-4cda-820d-abd4efaf33e8"
      },
      "source": [
        "MB.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['architecture', 'changement', 'disparité', 'espace de vie',\n",
              "       'localisation', 'taille', 'urbanisme', 'économie'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0agsKVacQ6L"
      },
      "source": [
        "#validation_croisee(X_w2v_mention.loc[index_not_norme,:].to_numpy(),annotations.loc[index_not_norme,:].procédé_de_nommage,LogisticRegression())\n",
        "clf = MLPClassifier(hidden_layer_sizes=100,max_iter=700)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYeywYCucQ6M"
      },
      "source": [
        "y_pred = cross_val_predict(clf,X=X_cible_m,y=y_cible_m)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prwLJdqodXax",
        "outputId": "72086f42-51eb-46fa-f992-d4a99f9d741b"
      },
      "source": [
        "report = classification_report(y_cible_m,y_pred,target_names=MB.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmWHL2H7djCa",
        "outputId": "0d86ee51-492e-4909-f738-3bd8cc91e6fe"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " architecture       1.00      0.81      0.89        21\n",
            "   changement       0.88      0.93      0.90        15\n",
            "    disparité       1.00      0.93      0.97        15\n",
            "espace de vie       0.93      0.62      0.74        21\n",
            " localisation       0.94      0.79      0.86        19\n",
            "       taille       0.88      0.93      0.90        15\n",
            "    urbanisme       0.72      0.87      0.79        15\n",
            "     économie       1.00      1.00      1.00        26\n",
            "\n",
            "    micro avg       0.92      0.86      0.89       147\n",
            "    macro avg       0.92      0.86      0.88       147\n",
            " weighted avg       0.93      0.86      0.88       147\n",
            "  samples avg       0.84      0.83      0.83       147\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFUmFx5JuJq"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b71O24-6JdV"
      },
      "source": [
        "path_model_cible_mention = '/content/drive/MyDrive/Stage Defense/Scripts/Modeles/cible_mention_model.sav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD7UNOmr5YJ1"
      },
      "source": [
        "pickle.dump(clf, open(path_model_cible_mention, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf__y011YjhW"
      },
      "source": [
        "## Polarité"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEhu-YGMdcY4"
      },
      "source": [
        "Regression Logistique supervisé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyH1AkGL_YiA",
        "outputId": "b268566a-1c22-4358-c36e-48f93deb0011"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# stopwords de nltk\n",
        "nltk_stopwords = set(stopwords.words('french'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL9xhUy1m4RO"
      },
      "source": [
        "import gensim\n",
        "from sklearn.metrics.pairwise import cosine_similarity "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmyyD6N3oBMy"
      },
      "source": [
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDadSTYbqdlo"
      },
      "source": [
        "chemin = \"/content/drive/MyDrive/Stage Defense\"\n",
        "cheminmodeleW2V = chemin+\"/Ressources/frWac_no_postag_no_phrase_500_cbow_cut100.bin\"\n",
        "model_frWac = gensim.models.KeyedVectors.load_word2vec_format(cheminmodeleW2V, binary=True, unicode_errors=\"ignore\")\n",
        "\n",
        "df_pola = pd.read_csv(chemin+\"/Ressources/polarité_mots.csv\",sep=\"\\t\",names=[\"mot\",\"POS\",\"polarité\",\"confiance\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vaPI6pk3_S5"
      },
      "source": [
        "mots_positifs = df_pola[(df_pola.polarité == \"POS\")&(df_pola.confiance!='0,33%')].mot.tolist()\n",
        "mots_negatifs = df_pola[(df_pola.polarité == \"NEG\")&(df_pola.confiance!='0,33%')].mot.tolist()\n",
        "mots_neutres = df_pola[(df_pola.polarité == \"NEUTRE\")&(df_pola.confiance!='0,33%')].mot.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaWfqdlPxPDG"
      },
      "source": [
        "def cos_sim(a,b):\n",
        "  return cosine_similarity(a.reshape(1, -1),b.reshape(1, -1))[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OC_h2xEmZIa"
      },
      "source": [
        "def moyenne_vecteurs(liste_mots):\n",
        "  liste_vecteurs = []\n",
        "  for mot in liste_mots:\n",
        "    if mot in model_frWac.vocab:\n",
        "      liste_vecteurs.append(model_frWac[mot])\n",
        "  return np.mean(np.array(liste_vecteurs),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OJo4jGTlpdl"
      },
      "source": [
        "vecteur_neutre = moyenne_vecteurs(mots_neutres)\n",
        "vecteur_positif = moyenne_vecteurs(mots_positifs)\n",
        "vecteur_negatif = moyenne_vecteurs(mots_negatifs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gss-PwJqknbb"
      },
      "source": [
        "def detecte_polarité(X,y,df):\n",
        "  y_pred = []\n",
        "  sims = []\n",
        "  for i, vecteur_mention in enumerate(X):\n",
        "    negativite = cos_sim(vecteur_mention,vecteur_negatif)\n",
        "    positivite = cos_sim(vecteur_mention,vecteur_positif)\n",
        "    neutralite = cos_sim(vecteur_mention,vecteur_neutre)\n",
        "    #print(df.iloc[i], negativite,neutralite,positivite, sep=\"\\t\")\n",
        "    choix_pola = {positivite:\"positif\",negativite:\"négatif\",neutralite:\"neutre\"}\n",
        "    #pola = choix_pola[max([positivite,negativite,neutralite])]\n",
        "    max_pola = max([positivite,negativite,neutralite])\n",
        "    if max_pola == positivite:\n",
        "      pola=\"positif\"\n",
        "    elif max_pola == negativite:\n",
        "      pola=\"négatif\"\n",
        "    else:\n",
        "      pola = \"neutre\"\n",
        "    y_pred.append(pola)\n",
        "    if y[i] == \"positif\":\n",
        "      print(negativite,neutralite,positivite)\n",
        "    #print(df.iloc[i], negativite,neutralite,positivite,max([positivite,negativite,neutralite]),choix_pola,pola,y[i], sep=\"\\t\")\n",
        "    sims.append([negativite,positivite,neutralite])\n",
        "  return y_pred,sims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSnraceo34R9"
      },
      "source": [
        "def detecte_polarité_sims(X,y):\n",
        "  y_pred = []\n",
        "  sims = []\n",
        "  for i, mention in enumerate(X):\n",
        "    doc = nlp(mention)\n",
        "    pola = \"neutre\"\n",
        "    negs,poss,neuts = [], [] , []\n",
        "    for token in doc:\n",
        "      if token.text == \"seul\": continue\n",
        "\n",
        "      if token.pos_ not in [\"ADV\",\"NOUN\",\"PROPN\",\"ADJ\",\"INTJ\",\"VERB\"] or token.lemma_ not in model_frWac.vocab or token.lemma_ in nltk_stopwords|{\"déjà\"}: continue\n",
        "      vecteur_token = model_frWac[token.lemma_]\n",
        "      negativite = cos_sim(vecteur_token,vecteur_negatif)\n",
        "      positivite = cos_sim(vecteur_token,vecteur_positif)\n",
        "      neutralite = cos_sim(vecteur_token,vecteur_neutre)\n",
        "      #print(df.iloc[i], negativite,neutralite,positivite, sep=\"\\t\")\n",
        "      choix_pola = {positivite:\"positif\",negativite:\"négatif\",neutralite:\"neutre\"}\n",
        "      #pola = choix_pola[max([positivite,negativite,neutralite])]\n",
        "      max_pola = max([positivite,negativite,neutralite])\n",
        "      negs.append(negativite)\n",
        "      poss.append(positivite)\n",
        "      neuts.append(negativite)\n",
        "      if y[i] == \"négatif\":\n",
        "        pass\n",
        "        #print(choix_pola, token.lemma_, mention)\n",
        "      if max_pola == positivite and positivite > 0.1:\n",
        "        \n",
        "        pola=\"positif\"\n",
        "        if y[i]!=\"positif\":\n",
        "          print(token, token.lemma_,positivite, neutralite, negativite, y[i], mention)\n",
        "        break\n",
        "      elif max_pola == negativite and  negativite > 0.1 :\n",
        "        pola=\"négatif\"\n",
        "        \n",
        "        #print(token, token.lemma_,positivite, neutralite, negativite, y[i], mention)\n",
        "        break\n",
        "      \n",
        "    y_pred.append(pola)\n",
        "    neg = max(negs) if negs else 0\n",
        "    neut = max(neuts) if neuts else 0\n",
        "    pos = max(poss) if poss else 0\n",
        "    sims.append([neg, neut,pos])\n",
        "    if y[i] == \"négatif\":\n",
        "      pass\n",
        "\n",
        "  return y_pred,sims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7I0EbsT7I1i"
      },
      "source": [
        "mentions_pola = annotations.loc[index_not_norme,\"mention\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa92MuFcoUb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8431193-81fa-4b8e-b736-72bef200bbb9"
      },
      "source": [
        "y_pred,sims = detecte_polarité_sims(mentions_pola,y_pola_m)\n",
        "print(classification_report(y_pola_m,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tours tour 0.2474078 0.1430674 0.0927223 neutre des tours\n",
            "tours tour 0.2474078 0.1430674 0.0927223 négatif des tours de bureaux froides et impersonnelles\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre les tours\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre des tours\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre des tours\n",
            "génération génération 0.19152321 0.028488718 0.0015842337 neutre La Défense nouvelle génération\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre les 70 tours et les sièges sociaux\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre aux tours\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre des tours\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre au pied des tours\n",
            "grâce grâce 0.3998186 0.17416021 0.26655558 neutre grâce au quartier d'affaires de la défense\n",
            "capitale capitale 0.1351002 0.08169999 0.04624751 neutre le quartier d'affaires de la capitale\n",
            "tours tour 0.2474078 0.1430674 0.0927223 neutre des tours\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      neutre       0.96      0.97      0.96       384\n",
            "     négatif       0.50      0.57      0.53         7\n",
            "     positif       0.72      0.69      0.70        48\n",
            "\n",
            "    accuracy                           0.93       439\n",
            "   macro avg       0.73      0.74      0.73       439\n",
            "weighted avg       0.93      0.93      0.93       439\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGdevaEjGKWQ"
      },
      "source": [
        "## Positionnement mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZpJdgeyGbqf"
      },
      "source": [
        "X_posit_m = dffeatures.loc[index_not_norme,\"contient_guillemet\"].to_numpy()\n",
        "y_posit_m = annotations.loc[index_not_norme,:].positionnement_mention.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66E2ToxLGNl0",
        "outputId": "9495bc3d-688a-42bc-97da-25e023aad1ca"
      },
      "source": [
        "y_pred_posit_m =  []\n",
        "for v in X_posit_m :\n",
        "  if v:\n",
        "    print(v)\n",
        "    y_pred_posit_m.append(\"cité\")\n",
        "  else:\n",
        "    y_pred_posit_m.append(\"pris en charge\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpKDXf1aH4-t",
        "outputId": "8a225a4e-9693-475d-a782-732dba00cbed"
      },
      "source": [
        "report = classification_report(y_posit_m,y_pred_posit_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48wWpeMWIPYb",
        "outputId": "28869fb9-be33-422e-e132-54f33e39402c"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "      attribué       0.00      0.00      0.00         1\n",
            "          cité       0.50      0.15      0.24        13\n",
            "pris en charge       0.97      1.00      0.98       425\n",
            "\n",
            "      accuracy                           0.97       439\n",
            "     macro avg       0.49      0.38      0.41       439\n",
            "  weighted avg       0.96      0.97      0.96       439\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYplEwI7KUQF"
      },
      "source": [
        "Conclusion : Impossible à déterminer sans le contexte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Thl1o_zo_r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}