{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EN_Classification_typologie_mention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWej5PIeUkSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62206ea-b13d-424f-8d62-afb175cc3c50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yStzFrSV5Nh5",
        "outputId": "52f98d9f-365d-48b7-e522-ca6b95da8135"
      },
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727026 sha256=8cf2bec68413cf999c4bf8bc16c2230f4651ddef9c14518e34cd5b0086338bf9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pl4t_mlh/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFy-O6KuU9Wr"
      },
      "source": [
        "chemincorpus = \"/content/drive/MyDrive/Stage Defense/Corpus/\"\n",
        "cheminw2v = chemincorpus + 'W2V_EN_mentions_Defense.csv'\n",
        "cheminbow = chemincorpus + 'BoW_EN_mentions_Defense.csv'\n",
        "cheminfeatures = chemincorpus +\"features_EN_mentions_Defense.csv\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptNzStLqTgf7"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjusRvUjTiUW"
      },
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEFPe4IUsNj"
      },
      "source": [
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nJ9xMp5Wb7b"
      },
      "source": [
        "Fonctions utiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY43qlPCWQiE"
      },
      "source": [
        "def equilibre_classes(X,y):\n",
        "  '''Retire aléatoirement des exemples des classes surnnuméraires, à la fois dans X et dans y\n",
        "  Renvoie X et y avec toutes les classes ayant le meme nombre d'exemple que la classe minoritaire'''\n",
        "  dicoclasses = {k:v for k,v in zip(*np.unique(y, return_counts=True))}\n",
        "  print(\"avant\",dicoclasses)\n",
        "  mini = min(dicoclasses.values())\n",
        "  while any((v >mini for v in dicoclasses.values())):\n",
        "    \n",
        "    for cat in dicoclasses:\n",
        "      if dicoclasses[cat] > mini:\n",
        "        nb_hasard = np.random.choice(np.where(y==cat)[0],1)\n",
        "        X = np.delete(X,nb_hasard, axis=0)\n",
        "        y = np.delete(y,nb_hasard, axis=0)\n",
        "        dicoclasses[cat]-=1\n",
        "\n",
        "  print(\"apres\",dicoclasses)\n",
        "  return X,y\n",
        "  #for i in range(len(X)):\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIcftOBuXESR"
      },
      "source": [
        "Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Zy4vn6XZiD"
      },
      "source": [
        "dfbow = pd.read_csv(cheminbow, sep=\",\",index_col=0)\n",
        "dfw2v = pd.read_csv(cheminw2v, sep=\",\",index_col=0)\n",
        "dffeatures = pd.read_csv(cheminfeatures, sep=\",\",index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WlRVNGFeEO5"
      },
      "source": [
        "chemindata = chemincorpus+\"Toutes_mentions_Defense_EN.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPUNMe4_eRYA"
      },
      "source": [
        "dfannot = pd.read_csv(chemindata,sep=\",\", index_col=0, keep_default_na=False,na_values=[\"NA\"])\n",
        "dfannot = dfannot[~(dfannot.cible_contexte.isin([\"\",np.NAN]))&(~dfannot.procédé_de_nommage.isin([\"\",np.NAN]))]\n",
        "annotations = dfannot.loc[:,:\"positionnement_contexte\"]\n",
        "annotations = annotations.fillna(\"NA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPuswClXdTlx"
      },
      "source": [
        "index_procede_rempli = annotations[annotations.procédé_de_nommage != \"NA\" ].index.intersection(dfbow.index).intersection(dffeatures.index)\n",
        "dffeatures = dffeatures.loc[index_procede_rempli,:]\n",
        "annotations = annotations.loc[index_procede_rempli,:]\n",
        "dfbow = dfbow.loc[index_procede_rempli,:]\n",
        "dfw2v = dfw2v.loc[index_procede_rempli,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KDcXMlZGgg"
      },
      "source": [
        "X_bow_mention = dfbow.iloc[:,:159]\n",
        "X_bow_contexte = dfbow.iloc[:,160:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cs8AdY6XJQr"
      },
      "source": [
        "X_w2v_mention = dfw2v.iloc[:,:500]\n",
        "X_w2v_contexte = dfw2v.iloc[:,501:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfpYQfc2Xu4l"
      },
      "source": [
        "# Predictions mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zv7wBNfao-g"
      },
      "source": [
        "def validation_croisee(X,y,clf):\n",
        "  y_pred = cross_val_predict(clf,X,y=y)\n",
        "  report = classification_report(y,y_pred)\n",
        "  print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDebb27xDxAO"
      },
      "source": [
        "def split_labels(y):\n",
        "  newy = []\n",
        "  for labels in y:\n",
        "    labelsplit = [label.strip() for label in labels.split(\"/\")]\n",
        "    if labelsplit == ['']:\n",
        "      print(labels)\n",
        "    newy.append(labelsplit)\n",
        "  return newy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V_yOxaFeT4M"
      },
      "source": [
        "## Procédé_nommage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dp_VpTPHXuU"
      },
      "source": [
        "### Extraction de la Norme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzr5i7zoeZ9z"
      },
      "source": [
        "def separe_norme(dffeatures):\n",
        "  index_normes = []\n",
        "  for i in dffeatures.index:\n",
        "    if dffeatures.loc[i,\"is_norme\"]:\n",
        "      index_normes.append(i)\n",
        "      #print(y.iloc[i,0])\n",
        "  return index_normes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js_M-7sLgolO"
      },
      "source": [
        "index_normes = separe_norme(dffeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoBGgbrBwnpD"
      },
      "source": [
        "df_pred = pd.DataFrame(index=annotations.index)\n",
        "df_pred[\"procédé_de_nommage\"] = \"autre\"\n",
        "df_pred[df_pred.index.isin(index_normes)]=\"norme\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foZblc6Byk0y"
      },
      "source": [
        "index_not_norme = annotations[~annotations.index.isin(index_normes)].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2n0ExuP-ORm"
      },
      "source": [
        "y_norme_autre = annotations.loc[:,\"procédé_de_nommage\"].copy()\n",
        "y_norme_autre.loc[index_not_norme] = \"autre\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hHQ5g0HINTy",
        "outputId": "0d8cd9f1-8725-40bc-ad8a-41cbcd19a715"
      },
      "source": [
        "print(classification_report(df_pred.procédé_de_nommage,y_norme_autre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       autre       1.00      1.00      1.00       197\n",
            "       norme       1.00      1.00      1.00       104\n",
            "\n",
            "    accuracy                           1.00       301\n",
            "   macro avg       1.00      1.00      1.00       301\n",
            "weighted avg       1.00      1.00      1.00       301\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FXs-zHfhgL-"
      },
      "source": [
        "for elem , e in zip(df_pred.procédé_de_nommage,y_norme_autre):\n",
        "  if elem != e :\n",
        "    print(\"u\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ8JTKLU-RTk"
      },
      "source": [
        "### Autres procédés de nommage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1mmXSl_38QY"
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiaKtdM8HdGF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aox4Nd7Qx_iY"
      },
      "source": [
        "Préparation données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTpJwZf_lgp9"
      },
      "source": [
        "index_not_norme = annotations[annotations.procédé_de_nommage!=\"norme\"].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDLZ-ULsCdFg"
      },
      "source": [
        "X_procédé = X_w2v_mention.loc[index_not_norme,:].to_numpy()\n",
        "X_procédé = dffeatures.loc[index_not_norme,\"contient_ordinal\":\"distance_norme\"].to_numpy()\n",
        "\n",
        "y_procédé = split_labels(annotations.loc[index_not_norme,\"procédé_de_nommage\"])\n",
        "\n",
        "MB = MultiLabelBinarizer()\n",
        "y_procédé = MB.fit_transform(y_procédé)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtVacMkuALxM"
      },
      "source": [
        "X_procédé,y_procédé = shuffle(X_procédé,y_procédé)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq_JOdsMo8-Y"
      },
      "source": [
        "#### Descripteurs Linguistiques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyZB6oCBohHi"
      },
      "source": [
        "Symbolique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCDIKyer_BRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c06b40-77b2-43d8-800f-570861cf97bf"
      },
      "source": [
        "y_pred_symbo = []\n",
        "for ordi,super,lieu,dist_lieu,geo,dist_geo,dist_norme in  X_procédé:\n",
        "  labels = [0,0,0,0]\n",
        "  if ordi or super:\n",
        "    labels[0] = 1\n",
        "  if lieu :\n",
        "    labels[3] = 1\n",
        "  if geo : \n",
        "    labels[2] = 1\n",
        "  if dist_geo < 0.5  and dist_lieu < 0.5 and dist_norme < 0.45:\n",
        "    print(dist_lieu,dist_geo,dist_norme)\n",
        "    labels[1] = 1\n",
        "  y_pred_symbo.append(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2660766541957855 0.3641175031661987 0.2859586179256439\n",
            "0.4539364278316498 0.33695077896118164 0.120164155960083\n",
            "0.4007566869258881 0.345424622297287 0.1265510320663452\n",
            "0.4577445685863495 0.3253185749053955 0.08519981801509857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VjMtEOZXBhM"
      },
      "source": [
        "report = classification_report(y_procédé,y_pred_symbo,target_names=MB.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk0w5ZIDbgpV",
        "outputId": "454c8a9e-f761-4385-f738-16e438537c74"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            classement       0.83      1.00      0.91         5\n",
            "             métaphore       0.25      0.33      0.29         3\n",
            "référence géographique       0.99      0.97      0.98       135\n",
            "             type lieu       0.98      0.99      0.99       171\n",
            "\n",
            "             micro avg       0.97      0.98      0.98       314\n",
            "             macro avg       0.76      0.82      0.79       314\n",
            "          weighted avg       0.98      0.98      0.98       314\n",
            "           samples avg       0.98      0.98      0.98       314\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6XAofdvZcW4"
      },
      "source": [
        "Statistique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwhRRXaVWZZ2"
      },
      "source": [
        "Descripteurs Linguistiques symbo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR3-ldo2h9FK"
      },
      "source": [
        "avec BoW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLStNslBYgzo"
      },
      "source": [
        "## Cible_mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlZS2OGyLtaw"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGdEDe08K9TA"
      },
      "source": [
        "def reequilibre_classes(X,y,cible_support):\n",
        "  \n",
        "  classes,counts = np.unique(np.array([label  for labels in y for label in labels]),return_counts=True)\n",
        "  dico_counts = {classe: count for classe,count in zip(classes,counts)}\n",
        "  dico_counts = dict(sorted(dico_counts.items(),key=lambda x:x[1] , reverse=True))\n",
        "  print(\"avant\", dico_counts)\n",
        "  #print(X)\n",
        "\n",
        "  new_X,new_y = [], []\n",
        "  if not isinstance(X,list):\n",
        "    X= X.tolist()\n",
        "  nb_sup,nb_add = 0,0\n",
        "  nb_total = len(X)\n",
        "  for label in dico_counts:\n",
        "    print(label,\"avant\", dico_counts)\n",
        "    while dico_counts[label]  < cible_support   or dico_counts[label]  > cible_support:\n",
        "      i = random.randint(0,len(y)-1)\n",
        "      labels = y[i]\n",
        "      if label not in labels : continue\n",
        "      if dico_counts[label] < cible_support :\n",
        "        for lab in labels:\n",
        "          dico_counts[lab] +=1\n",
        "        X.append(X[i])\n",
        "        y.append(y[i])\n",
        "        nb_add +=1\n",
        "      elif dico_counts[label] > cible_support :\n",
        "        if any((dico_counts[lab] < cible_support-5 for lab in labels) ): continue\n",
        "        for lab in labels:\n",
        "          dico_counts[lab] -=1\n",
        "        del X[i]\n",
        "        del y[i]\n",
        "        nb_sup+=1\n",
        "    \n",
        "    print(label,\"après\", dico_counts)\n",
        "\n",
        "  classes,counts = np.unique(np.array([label  for labels in y for label in labels]),return_counts=True)\n",
        "  dico_counts = {classe: count for classe,count in zip(classes,counts)}\n",
        "  print(f\"exemples avant : {nb_total}\", f\"ajoutés : {nb_add}\", f\"supprimés : {nb_sup}\", f\"exemples après : {len(X)}\", sep = \" | \")\n",
        "  return X,y\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  new_dico_counts =   {classe: count for classe,count in zip(*np.unique(np.array([label  for labels in new_y for label in labels]),return_counts=True))}\n",
        "  print(\"a la fin\",new_dico_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuUaQ6Z8YlPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5764aaa3-c015-4b13-8527-2d788a7f4e8d"
      },
      "source": [
        "X_cible_m = X_w2v_mention.loc[index_not_norme,:].to_numpy()\n",
        "y_cible_m = split_labels(annotations.loc[index_not_norme,:].cible_mention)\n",
        "X_cible_m, y_cible_m =reequilibre_classes(X_cible_m,y_cible_m,10)\n",
        "MB = MultiLabelBinarizer()\n",
        "y_cible_m = MB.fit_transform(y_cible_m)\n",
        "X_cible_m,y_cible_m = shuffle(X_cible_m,y_cible_m)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avant {'économie': 147, 'localisation': 125, 'taille': 10, 'urbanisme': 7, 'architecture': 6, 'changement': 5, 'disparité': 1, 'espace de vie': 1}\n",
            "économie avant {'économie': 147, 'localisation': 125, 'taille': 10, 'urbanisme': 7, 'architecture': 6, 'changement': 5, 'disparité': 1, 'espace de vie': 1}\n",
            "économie après {'économie': 10, 'localisation': 51, 'taille': 4, 'urbanisme': 7, 'architecture': 4, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "localisation avant {'économie': 10, 'localisation': 51, 'taille': 4, 'urbanisme': 7, 'architecture': 4, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "localisation après {'économie': 6, 'localisation': 10, 'taille': 4, 'urbanisme': 4, 'architecture': 4, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "taille avant {'économie': 6, 'localisation': 10, 'taille': 4, 'urbanisme': 4, 'architecture': 4, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "taille après {'économie': 8, 'localisation': 14, 'taille': 10, 'urbanisme': 4, 'architecture': 4, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "urbanisme avant {'économie': 8, 'localisation': 14, 'taille': 10, 'urbanisme': 4, 'architecture': 4, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "urbanisme après {'économie': 8, 'localisation': 14, 'taille': 10, 'urbanisme': 10, 'architecture': 8, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "architecture avant {'économie': 8, 'localisation': 14, 'taille': 10, 'urbanisme': 10, 'architecture': 8, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "architecture après {'économie': 9, 'localisation': 15, 'taille': 10, 'urbanisme': 11, 'architecture': 10, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "changement avant {'économie': 9, 'localisation': 15, 'taille': 10, 'urbanisme': 11, 'architecture': 10, 'changement': 4, 'disparité': 1, 'espace de vie': 1}\n",
            "changement après {'économie': 12, 'localisation': 18, 'taille': 10, 'urbanisme': 11, 'architecture': 10, 'changement': 10, 'disparité': 1, 'espace de vie': 1}\n",
            "disparité avant {'économie': 12, 'localisation': 18, 'taille': 10, 'urbanisme': 11, 'architecture': 10, 'changement': 10, 'disparité': 1, 'espace de vie': 1}\n",
            "disparité après {'économie': 21, 'localisation': 18, 'taille': 10, 'urbanisme': 11, 'architecture': 19, 'changement': 10, 'disparité': 10, 'espace de vie': 1}\n",
            "espace de vie avant {'économie': 21, 'localisation': 18, 'taille': 10, 'urbanisme': 11, 'architecture': 19, 'changement': 10, 'disparité': 10, 'espace de vie': 1}\n",
            "espace de vie après {'économie': 21, 'localisation': 18, 'taille': 10, 'urbanisme': 11, 'architecture': 19, 'changement': 10, 'disparité': 10, 'espace de vie': 10}\n",
            "exemples avant : 197 | ajoutés : 38 | supprimés : 178 | exemples après : 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO0OYz4brjJA",
        "outputId": "8669b39f-89be-4c49-a504-55ff490c71ef"
      },
      "source": [
        "MB.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['architecture', 'changement', 'disparité', 'espace de vie',\n",
              "       'localisation', 'taille', 'urbanisme', 'économie'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJIEM9rPZSBm"
      },
      "source": [
        "Apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBjXbEHcQx9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0agsKVacQ6L"
      },
      "source": [
        "#validation_croisee(X_w2v_mention.loc[index_not_norme,:].to_numpy(),annotations.loc[index_not_norme,:].procédé_de_nommage,LogisticRegression())\n",
        "clf = MLPClassifier(hidden_layer_sizes=100,max_iter=400)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYeywYCucQ6M",
        "outputId": "843d68ae-82fa-421d-b2e6-2156efda5f21"
      },
      "source": [
        "y_pred = cross_val_predict(clf,X=X_cible_m,y=y_cible_m)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prwLJdqodXax"
      },
      "source": [
        "report = classification_report(y_cible_m,y_pred,target_names=MB.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rZ9vuzviUhM"
      },
      "source": [
        "w2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmWHL2H7djCa",
        "outputId": "fd92a06c-0f2b-4ede-f612-67f68e940348"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " architecture       1.00      0.95      0.97        19\n",
            "   changement       1.00      1.00      1.00        10\n",
            "    disparité       1.00      1.00      1.00        10\n",
            "espace de vie       0.91      1.00      0.95        10\n",
            " localisation       1.00      1.00      1.00        18\n",
            "       taille       1.00      0.70      0.82        10\n",
            "    urbanisme       0.91      0.91      0.91        11\n",
            "     économie       0.83      0.95      0.89        21\n",
            "\n",
            "    micro avg       0.94      0.94      0.94       109\n",
            "    macro avg       0.96      0.94      0.94       109\n",
            " weighted avg       0.95      0.94      0.94       109\n",
            "  samples avg       0.94      0.94      0.94       109\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h1UcBkRiZ4F"
      },
      "source": [
        "Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf__y011YjhW"
      },
      "source": [
        "## Polarité"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RldUedUKcWdH"
      },
      "source": [
        "### Avec Textblob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVu82S2CfjFi",
        "outputId": "5e520a1c-e689-4abd-dab3-1f424cc6df8d"
      },
      "source": [
        "!pip install -U textblob-fr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textblob-fr\n",
            "  Downloading textblob_fr-0.2.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 81 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 122 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 163 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 174 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 204 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 215 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 256 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 286 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 296 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 307 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 327 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 337 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 348 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 378 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 389 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 409 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 419 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 430 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 450 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 460 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 471 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 481 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 501 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 512 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 522 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 532 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 542 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 552 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 561 kB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: textblob>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from textblob-fr) (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob>=0.8.0->textblob-fr) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob>=0.8.0->textblob-fr) (1.15.0)\n",
            "Installing collected packages: textblob-fr\n",
            "Successfully installed textblob-fr-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv--5mkKciHD"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0miBxruDcYrY",
        "outputId": "12c5d45c-24bd-48cd-a3d7-e2be22771349"
      },
      "source": [
        "y_pred_pola = []\n",
        "for mention,classe in zip(mentions_pola,y_pola_m):\n",
        "  doc = nlp(mention)\n",
        "  for token in doc:\n",
        "    blob = TextBlob(token.lemma_)\n",
        "    #blob = TextBlob(mention)\n",
        "    sentiments = blob.sentiment\n",
        "    #print(sentiments,mention)\n",
        "    pola = sentiments[0]\n",
        "    if pola <0:\n",
        "      \n",
        "      pola_pred = \"négatif\"\n",
        "      break\n",
        "    elif pola > 0:\n",
        "      \n",
        "      pola_pred = \"positif\"\n",
        "      break\n",
        "    else:\n",
        "      \n",
        "      pola_pred =\"neutre\"\n",
        "  if pola_pred != classe:\n",
        "    print(sentiments,mention, pola_pred, \"|\", classe)\n",
        "  y_pred_pola.append(pola_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=0.2, subjectivity=0.3) the French capital's modern business district positif | neutre\n",
            "Sentiment(polarity=0.0, subjectivity=0.0) Prime office space in the centre of Paris neutre | positif\n",
            "Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453) its new post-Brexit home positif | neutre\n",
            "Sentiment(polarity=0.16, subjectivity=0.5399999999999999) the high-rise business district on the western outskirts of Paris positif | neutre\n",
            "Sentiment(polarity=0.0, subjectivity=0.0) Paris's safety valve for office space neutre | positif\n",
            "Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453) Paris's then-new business district positif | neutre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrjbby-oh6R1",
        "outputId": "ff27a074-63e3-4ba7-8faf-384c091f8d9b"
      },
      "source": [
        "print(classification_report(y_pola_m,y_pred_pola))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      neutre       0.99      0.98      0.98       182\n",
            "     négatif       1.00      1.00      1.00         1\n",
            "     positif       0.75      0.86      0.80        14\n",
            "\n",
            "    accuracy                           0.97       197\n",
            "   macro avg       0.91      0.95      0.93       197\n",
            "weighted avg       0.97      0.97      0.97       197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGdevaEjGKWQ"
      },
      "source": [
        "## Positionnement mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZpJdgeyGbqf"
      },
      "source": [
        "X_posit_m = dffeatures.loc[index_not_norme,\"contient_guillemet\"].to_numpy()\n",
        "y_posit_m = annotations.loc[index_not_norme,:].positionnement_mention.to_numpy(dtype='str')\n",
        "y_posit_m = np.char.replace(np.char.strip(y_posit_m), \"prise\",\"pris\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66E2ToxLGNl0"
      },
      "source": [
        "y_pred_posit_m =  []\n",
        "for v in X_posit_m :\n",
        "  if v:\n",
        "    print(v)\n",
        "    y_pred_posit_m.append(\"cité\")\n",
        "  else:\n",
        "    y_pred_posit_m.append(\"pris en charge\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpKDXf1aH4-t",
        "outputId": "07df1afc-5f04-43b0-e588-70ba3406d783"
      },
      "source": [
        "report = classification_report(y_posit_m,y_pred_posit_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48wWpeMWIPYb",
        "outputId": "e7c946fc-2fda-4463-ff7d-ad65a0a07c73"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "          cité       0.00      0.00      0.00         6\n",
            "pris en charge       0.97      1.00      0.98       191\n",
            "\n",
            "      accuracy                           0.97       197\n",
            "     macro avg       0.48      0.50      0.49       197\n",
            "  weighted avg       0.94      0.97      0.95       197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}